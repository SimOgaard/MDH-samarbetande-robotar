{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainingLego.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPa80+gCCNLMfctHY3GhBt5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MI3-Q21u8FHh"},"source":["# TODO:\n","1.   Distort images: (gritty, dark, noise) using imgaug\n","2.   Retrain on theese images\n","3.   Test the old CNN agaisnt the new ones on theese images\n","\n","## this is done and this is the results\n","\n","### weakest model trained on new images:\n","\n","{'fscore': 0.8493919550982226, 'precision': 0.8598484848484849, 'recall': 0.8391866913123844}\n","Average prediction time:5.35787731768137 ms\n","\n","### less weak model trained on new images: \n","\n","{'fscore': 0.9339449541284405, 'precision': 0.9271402550091075, 'recall': 0.9408502772643254}\n","Average prediction time:5.5791603992263 ms\n","\n","### weakest model trained on normal images:\n","\n","{'fscore': 0.5445462114904247, 'precision': 0.4954545454545455, 'recall': 0.6044362292051756}\n","Average prediction time:5.511541443177495 ms\n","\n","### strongest model trained on normal images:\n","\n","{'fscore': 0.5556831228473019, 'precision': 0.7333333333333333, 'recall': 0.44731977818853974}\n","Average prediction time:6.131902755982426 ms\n","\n","\n","# IMPORTANT: theese are old values.\n","#### New lego characters are now beeing trained on (the ones we will actually look for in the end). However the old model was able to detect them without beeing trained on them. With about 60-70% precision. Altough the stronger model was needed, and it missread some objects as lego characters.\n","\n"]},{"cell_type":"code","metadata":{"id":"r8INP1Svc3Ml","executionInfo":{"status":"ok","timestamp":1601103355048,"user_tz":-120,"elapsed":974,"user":{"displayName":"Zhyos Games","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4cAQaPku0EzaDwJPkq-CSrAkuxN6anUCUn3VIrg=s64","userId":"06273927556887840173"}},"outputId":"f062de5b-0ddd-489c-b76e-8be7a9cd3a0a","colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["!nvidia-smi # You want 16280MiB, just hardreset runtime and run again."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sat Sep 26 06:55:54 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wd4hHE4Ljcd8"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"JwpIkj1kc6yD"},"source":["%tensorflow_version 1.x\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!mkdir /content/drive/My\\ Drive/ModelsH5\n","\n","!mkdir /content/GeneratedDataset\n","!mkdir /content/GeneratedDataset/GeneratedImages\n","!mkdir /content/GeneratedDataset/GeneratedImagesXml\n","!mkdir /content/GeneratedDataset/GeneratedImages_validation\n","!mkdir /content/GeneratedDataset/GeneratedImagesXml_validation\n","\n","!wget https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\n","!tar xf dtd-r1.0.1.tar.gz\n","!rm /content/dtd-r1.0.1.tar.gz\n","\n","!git clone https://github.com/AIWintermuteAI/aXeleRate.git\n","!pip uninstall -y imgaug && pip uninstall -y albumentations && pip install imgaug==0.4\n","\n","%cd /content/\n","!mkdir /content/Yolo-digit-detector\n","%cd /content/Yolo-digit-detector\n","!git clone https://github.com/abbsimoga/MDH-samarbetande-robotar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qEQwd0xd8fi"},"source":["%cd /content\n","from keras import backend as K\n","import sys\n","sys.path.append('/content/aXeleRate')\n","from axelerate import setup_training, setup_inference\n","import os\n","\n","actual_epoch = 20\n","learning_rate = 1e-4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3CvPnL2eaJU","executionInfo":{"status":"ok","timestamp":1601103436844,"user_tz":-120,"elapsed":67051,"user":{"displayName":"Zhyos Games","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4cAQaPku0EzaDwJPkq-CSrAkuxN6anUCUn3VIrg=s64","userId":"06273927556887840173"}}},"source":["def get_model_path(model_path_txt):\n","    f = open(model_path_txt, \"r\")\n","    model_path = f.read()\n","    f.close()\n","    return model_path\n","\n","def get_config(model_path, architecture, batch_size, saved_folder, actual_epoch, learning_rate):\n","    config = {\n","            \"model\":{\n","                \"type\":             \"Detector\",\n","                \"architecture\":     architecture,\n","                \"input_size\":       224,\n","                \"anchors\":          [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828],\n","                \"labels\":           [\"lego gubbe\"],\n","                \"coord_scale\" : \t\t1.0,\n","                \"class_scale\" : \t\t1.0,\n","                \"object_scale\" : \t\t5.0,\n","                \"no_object_scale\" : 1.0\n","            },\n","            \"weights\" : {\n","                \"full\":   \t\t\t\t  model_path,\n","                \"backend\":   \t\t    \"imagenet\"\n","            },\n","            \"train\" : {\n","                \"actual_epoch\":         actual_epoch,\n","                \"train_image_folder\":   \"/content/GeneratedDataset/GeneratedImages\",\n","                \"train_annot_folder\":   \"/content/GeneratedDataset/GeneratedImagesXml\",\n","                \"train_times\":          1,\n","                \"valid_image_folder\":   \"/content/GeneratedDataset/GeneratedImages_validation\",\n","                \"valid_annot_folder\":   \"/content/GeneratedDataset/GeneratedImagesXml_validation\",\n","                \"valid_times\":          1,\n","                \"valid_metric\":         \"mAP\",\n","                \"batch_size\":           batch_size,\n","                \"learning_rate\":        learning_rate,\n","                \"saved_folder\":   \t    saved_folder,\n","                \"first_trainable_layer\":\"\",\n","                \"augumentation\":\t\t\t\tFalse,\n","                \"is_only_detect\" : \t\t  False\n","            },\n","            \"converter\" : {\n","                \"type\":   \t\t\t\t[\"k210\",\"kmodel\"]\n","            }\n","    }\n","\n","    return config"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHgFjzPhTMKB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UFCl07r4SgQ-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loLb4arxiyGW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdlwdjEfPM5b","executionInfo":{"status":"ok","timestamp":1601103436845,"user_tz":-120,"elapsed":64632,"user":{"displayName":"Zhyos Games","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4cAQaPku0EzaDwJPkq-CSrAkuxN6anUCUn3VIrg=s64","userId":"06273927556887840173"}}},"source":["# utilizing threading:\n","# time: 40.67213749885559 per1k: 40.672142028808594 per1: 0.040672143697738646\n","\n","\n","# utilizing gpu:\n","# time: 37.83721184376 per1k: 37.83721184376 per1: 0.03783721184376001\n","\n","\n","# utilizing multiproccesing:\n","# time: 19.642900943756104 per1k: 19.642902135849 per1: 0.019642902851104736\n","\n","\n","# somthing changes inbetween this value and the next and i cant figure out what, its a lot slower now\n","# expected time increese (around 8 seconds), but it jumped to:\n","\n","\n","# using augmentation the time increeses significantly to around:\n","# time: 33.92477869987488 per1k: 33.924779415130615 per1: 0.03392478013038635\n","\n","\n","### IMPORTANT:\n","# this is an old way that i created images to train on, a way better one i did with card detection can be found @:\n","# https://drive.google.com/file/d/1AF1ElrFIrhH1V4A_hkdC7oedH2chb5vZ/view?usp=sharing\n","# but couldnt bother to change this one, since heavy time restriction\n","\n","\n","minSize = 28\n","maxSize = 112\n","maxCharactersAllowed = 6\n","\n","import cv2\n","import imutils\n","import os\n","import random\n","import numpy as np\n","import xml.etree.cElementTree as ET\n","from glob import glob\n","import time\n","import timeit\n","import concurrent.futures\n","import imgaug.augmenters as iaa\n","\n","seq = iaa.Sequential([\n","    iaa.Add((-40, 15), per_channel=0.5),\n","    iaa.AdditiveGaussianNoise(scale=(0, 0.10*255), per_channel=True),\n","    iaa.CoarseSaltAndPepper(0.025, size_percent=(0.01, 0.08), per_channel=True),\n","    iaa.JpegCompression(compression=(10, 35))\n","])\n","\n","def create_root(file_prefix, width, height):\n","    root = ET.Element(\"annotations\")\n","    ET.SubElement(root, \"filename\").text = \"{}.JPEG\".format(file_prefix)\n","    ET.SubElement(root, \"folder\").text = \"images\"\n","    size = ET.SubElement(root, \"size\")\n","    ET.SubElement(size, \"width\").text = str(width)\n","    ET.SubElement(size, \"height\").text = str(height)\n","    ET.SubElement(size, \"depth\").text = \"3\"\n","    return root\n"," \n","def create_object_annotation(root, voc_labels):\n","    for voc_label in voc_labels:\n","        obj = ET.SubElement(root, \"object\")\n","        ET.SubElement(obj, \"name\").text = voc_label[0]\n","        ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n","        ET.SubElement(obj, \"truncated\").text = str(0)\n","        ET.SubElement(obj, \"difficult\").text = str(0)\n","        bbox = ET.SubElement(obj, \"bndbox\")\n","        ET.SubElement(bbox, \"xmin\").text = str(voc_label[1])\n","        ET.SubElement(bbox, \"ymin\").text = str(voc_label[2])\n","        ET.SubElement(bbox, \"xmax\").text = str(voc_label[3])\n","        ET.SubElement(bbox, \"ymax\").text = str(voc_label[4])\n","    return root\n","\n","def create_images(itterations): \n","    if itterations % 10000 == 0:\n","        print(\"Current images:\",itterations)\n","    charactersOnCanvas = []\n","    resizedBackground=cv2.resize(cv2.cvtColor(cv2.imread(random.choice(glob(\"/content/dtd/images/*/*.jpg\"))), cv2.COLOR_RGB2RGBA),(224,224))\n","\n","    charactersAmount = random.randint(1, maxCharactersAllowed)\n","    for amounts in range(charactersAmount):\n","        skip = False\n","        characterDir = \"/content/Yolo-digit-detector/MDH-samarbetande-robotar/OpenMV/YoloObjDetection/lego-gubbar-detection/Edit Characters/FramesNoBackground/\"+random.choice(os.listdir(\"/content/Yolo-digit-detector/MDH-samarbetande-robotar/OpenMV/YoloObjDetection/lego-gubbar-detection/Edit Characters/FramesNoBackground\"))\n","        imgCharacter = cv2.imread(characterDir, cv2.IMREAD_UNCHANGED)\n","\n","        rotation = random.randint(0,360)\n","        rotatedCharacter = imutils.rotate_bound(imgCharacter, rotation)\n","\n","        largeSide = max([rotatedCharacter.shape[1], rotatedCharacter.shape[0]])\n","        maxScale = int((maxSize/largeSide)*100)\n","        minScale = int((minSize/largeSide)*100)\n","        scalePercent = random.randint(minScale, maxScale)\n","        resizedCharacter = cv2.resize(rotatedCharacter, (int(rotatedCharacter.shape[1]*scalePercent/100),int(rotatedCharacter.shape[0]*scalePercent/100)))\n","\n","        y_offset = random.randint(0, resizedBackground.shape[0]-resizedCharacter.shape[0])\n","        x_offset = random.randint(0, resizedBackground.shape[1]-resizedCharacter.shape[1])\n","        y1, y2 = y_offset, y_offset + resizedCharacter.shape[0]\n","        x1, x2 = x_offset, x_offset + resizedCharacter.shape[1]\n","\n","        alpha_s = resizedCharacter[:, :, 3] / 255.0\n","        alpha_l = 1.0 - alpha_s\n","\n","        if charactersOnCanvas:\n","            for _, x1_, y1_, x2_, y2_ in charactersOnCanvas:\n","                if x2_ < x1 or x2 < x1_ or y2_ < y1 or y2 < y1_:\n","                    continue                \n","                skip=True\n","                break\n","            \n","        if skip:\n","            continue\n","\n","        for c in range(0, 3):\n","            resizedBackground[y1:y2, x1:x2, c] = (alpha_s * resizedCharacter[:, :, c] + alpha_l * resizedBackground[y1:y2, x1:x2, c])\n","\n","        charactersOnCanvas.append([\"lego gubbe\", x1, y1, x2, y2])\n","\n","    file_prefix = str(itterations).zfill(8)\n","    root = create_root(file_prefix, resizedBackground.shape[0], resizedBackground.shape[1])\n","    root = create_object_annotation(root, charactersOnCanvas)\n","    tree = ET.ElementTree(root) \n","    \n","    tree.write(\"/content/GeneratedDataset/GeneratedImagesXml{}/{}.xml\".format(\"_validation\" if validation else \"\", file_prefix))\n","    # cv2.imwrite(\"/content/GeneratedDataset/GeneratedImages{}/{}.JPEG\".format(\"_validation\" if validation else \"\", file_prefix), resizedBackground)\n","    cv2.imwrite(\"/content/GeneratedDataset/GeneratedImages{}/{}.JPEG\".format(\"_validation\" if validation else \"\", file_prefix), seq(image=resizedBackground[:, :, :3]))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9DKBGHtql6_h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccvGNBs5mNd7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cJt8bd3xB9_d"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NN6MaCKBrCV3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5PvoftZ4j694"},"source":["# Select model"]},{"cell_type":"markdown","metadata":{"id":"v1e5Ra8CXalS"},"source":["#### Possible models\n","\n","##### Any model bigger than MobileNet5_0 usualy crashes when paired with other algorythms like, findblob/lineregression\n","\n","- Full Yolo\n","- Tiny Yolo\n","- MobileNet1_0\n","- MobileNet7_5\n","- MobileNet5_0 (Recommended) slower better results\n","- MobileNet2_5 (Recommended) faster worse results\n","- SqueezeNet\n","- NASNetMobile\n","- DenseNet121\n","- ResNet50\n","\n","#### Exact training values of each model can be found underneath"]},{"cell_type":"markdown","metadata":{"id":"X3RwbLJedD0_"},"source":["### MobileNet2_5\n","*   Average runtime: 5.078327224915286 ms\n","*   Fscore:          0.9118483412322275\n","*   Precision:       0.9232245681381958\n","*   Recall:          0.900749063670412\n","*   Model size:      226,254"]},{"cell_type":"code","metadata":{"id":"2qMWcvgZdCa4"},"source":["!mkdir /content/drive/My\\ Drive/ModelsH5/MobileNet2_5\n","\n","architecture = \"MobileNet2_5\"\n","batch_size = 384\n","\n","saved_folder = \"/content/drive/My Drive/ModelsH5/MobileNet2_5\"\n","model_path_txt = \"/content/drive/My Drive/ModelsH5/MobileNet2_5/model_path.txt\"\n","\n","if not os.path.isfile(model_path_txt):\n","    f = open(model_path_txt,\"w+\")\n","    f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DVtJCI5jgtLn"},"source":["### MobileNet5_0\n","\n","*   Average runtime: 5.546079581999875 ms\n","*   Fscore:          0.976657329598506\n","*   Precision:       0.9739292364990689\n","*   Recall:          0.9794007490636704\n","*   Model size:      844 926"]},{"cell_type":"code","metadata":{"id":"dY4pOi6XgyLS","executionInfo":{"status":"ok","timestamp":1601103436846,"user_tz":-120,"elapsed":61369,"user":{"displayName":"Zhyos Games","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4cAQaPku0EzaDwJPkq-CSrAkuxN6anUCUn3VIrg=s64","userId":"06273927556887840173"}}},"source":["!mkdir /content/drive/My\\ Drive/ModelsH5/MobileNet5_0\n","\n","architecture = \"MobileNet5_0\"\n","batch_size = 192\n","\n","saved_folder = \"/content/drive/My Drive/ModelsH5/MobileNet5_0\"\n","model_path_txt = \"/content/drive/My Drive/ModelsH5/MobileNet5_0/model_path.txt\"\n","\n","if not os.path.isfile(model_path_txt):\n","    f = open(model_path_txt,\"w+\")\n","    f.close()"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SVADfjqFhNNX"},"source":["### MobileNet7_5\n","*   Average runtime: 6.327065119302895 ms\n","*   Fscore:          0.9804287045666357\n","*   Precision:       0.9758812615955473\n","*   Recall:          0.9850187265917603\n","*   Model size:      1 856 046"]},{"cell_type":"code","metadata":{"id":"8VDqcKrrhOk2"},"source":["!mkdir /content/drive/My\\ Drive/ModelsH5/MobileNet7_5\n","\n","architecture = \"MobileNet7_5\"\n","batch_size = 192\n","\n","saved_folder = \"/content/drive/My Drive/ModelsH5/MobileNet7_5\"\n","model_path_txt = \"/content/drive/My Drive/ModelsH5/MobileNet7_5/model_path.txt\"\n","\n","if not os.path.isfile(model_path_txt):\n","    f = open(model_path_txt,\"w+\")\n","    f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UbIDYiuIhoLT"},"source":["### MobileNet1_0\n","*   Average runtime: 7.210679801113634 ms\n","*   Fscore:          0.9915651358950328\n","*   Precision:       0.9924953095684803\n","*   Recall:          0.9906367041198502\n","*   Model size:      3 259 614"]},{"cell_type":"code","metadata":{"id":"0FKDQPY6hph5"},"source":["!mkdir /content/drive/My\\ Drive/ModelsH5/MobileNet1_0\n","\n","architecture = \"MobileNet1_0\"\n","batch_size = 192\n","\n","saved_folder = \"/content/drive/My Drive/ModelsH5/MobileNet1_0\"\n","model_path_txt = \"/content/drive/My Drive/ModelsH5/MobileNet1_0/model_path.txt\"\n","\n","if not os.path.isfile(model_path_txt):\n","    f = open(model_path_txt,\"w+\")\n","    f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQM6vT_5ipy2"},"source":["#  Train"]},{"cell_type":"markdown","metadata":{"id":"NPWYgxWwcsF3"},"source":["### IMPORTANT:\n","#### This is not 100% set time, its an aproximation\n","#### expect to wait LONGER for training and to create the dataset \n","\n","Creating 100 000 images takes 45 min\n","\n","Training time depends on model but can aproximate to 175 min on large model, 135 on MobileNet2_5"]},{"cell_type":"markdown","metadata":{"id":"KYTmm_QE0bzF"},"source":["### Train 1 time\n","#### (recommended)"]},{"cell_type":"code","metadata":{"id":"wgIVny5u0sFz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uLGTN-djioYv"},"source":["actual_epoch = 20\n","validation = False\n","start_time = time.time()\n","pool = concurrent.futures.ProcessPoolExecutor(max_workers=None)\n","pool.map(create_images, range(150000))\n","pool.shutdown(wait=True)\n","print(\"time:\",time.time()-start_time,\"per1k:\",(time.time()-start_time)/100,\"per1:\",(time.time()-start_time)/100000)\n","\n","validation = True\n","start_time = time.time()\n","pool = concurrent.futures.ProcessPoolExecutor(max_workers=None)\n","pool.map(create_images, range(1000))\n","pool.shutdown(wait=True)\n","print(\"time:\",time.time()-start_time,\"per1k:\",(time.time()-start_time)/1,\"per1:\",(time.time()-start_time)/1000)\n","\n","model_path = get_model_path(model_path_txt)\n","config = get_config(model_path, architecture, batch_size, saved_folder, actual_epoch, learning_rate)\n","\n","K.clear_session()\n","model_path = setup_training(config_dict=config)\n","\n","f = open(model_path_txt, \"w\")\n","f.write(model_path)\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mmSaEBsS0hKy"},"source":["### Train to your heart's content\n","#### creates a smaller dataset and trains for fewer epochs to be able to change models learning rate inbetween.\n","\n","### IMPORTANT\n","#### this loop will never break but your model will be saved after each itteration"]},{"cell_type":"code","metadata":{"id":"VnxCunUZ0pws"},"source":["actual_epoch = 5\n","\n","while True:\n","    validation = False\n","    start_time = time.time()\n","    pool = concurrent.futures.ProcessPoolExecutor(max_workers=None)\n","    pool.map(create_images, range(50000))\n","    pool.shutdown(wait=True)\n","    print(\"time:\",time.time()-start_time,\"per1k:\",(time.time()-start_time)/50,\"per1:\",(time.time()-start_time)/50000)\n","\n","    validation = True\n","    start_time = time.time()\n","    pool = concurrent.futures.ProcessPoolExecutor(max_workers=None)\n","    pool.map(create_images, range(1000))\n","    pool.shutdown(wait=True)\n","    print(\"time:\",time.time()-start_time,\"per1k:\",(time.time()-start_time)/1,\"per1:\",(time.time()-start_time)/1000)\n","\n","\n","    model_path = get_model_path(model_path_txt)\n","    config = get_config(model_path, architecture, batch_size, saved_folder, actual_epoch, learning_rate)\n","\n","    K.clear_session()\n","    model_path = setup_training(config_dict=config)\n","\n","    f = open(model_path_txt, \"w\")\n","    f.write(model_path)\n","    f.close()\n","\n","    learning_rate = learning_rate/1.5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZL4rD4iIjJ9Y"},"source":["# Convert"]},{"cell_type":"code","metadata":{"id":"9XYp-WlzjNjb"},"source":["f = open(model_path_txt, \"r\")\n","model_path = f.read()\n","f.close()\n","\n","validation = True\n","start_time = time.time()\n","pool = concurrent.futures.ProcessPoolExecutor(max_workers=None)\n","pool.map(create_images, range(1000))\n","pool.shutdown(wait=True)\n","print(\"time:\",time.time()-start_time,\"per1k:\",(time.time()-start_time)/1,\"per1:\",(time.time()-start_time)/1000)\n","\n","%cd /content\n","!git clone https://github.com/sipeed/Maix_Toolbox\n","%cd /content/Maix_Toolbox\n","!bash get_nncase.sh\n","%cd /content/Maix_Toolbox/ncc\n","!tar -xJf /content/Maix_Toolbox/ncc/ncc-linux-x86_64.tar.xz\n","!rm ncc-linux-x86_64.tar.xz\n","\n","%cd /content/Maix_Toolbox \n","\n","!cp -a /content/GeneratedDataset/GeneratedImages_validation/. /content/Maix_Toolbox/images/\n","\n","!rm tflite2kmodel.sh\n","!wget https://raw.githubusercontent.com/abbjoafli/ComputerVision/master/files/tflite2kmodel.sh\n","\n","!cp {\"/content/drive/My\\ Drive/ModelsH5/\"+model_path[33:-17]+\"/YOLO_best_mAP.tflite\"} /content/Maix_Toolbox/\n","\n","!bash tflite2kmodel.sh /content/Maix_Toolbox/YOLO_best_mAP.tflite /content/Maix_Toolbox/YOLO_best_mAP.kmodel -i tflite -o kmodel -t k210 --dataset /content/Maix_Toolbox/images\n","\n","!cp /content/Maix_Toolbox/YOLO_best_mAP.kmodel {\"/content/drive/My\\ Drive/ModelsH5/\"+model_path[33:-17]}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i2ubE4C8jOpT"},"source":["\n","# Evaluate"]},{"cell_type":"code","metadata":{"id":"sHCmpWuPjTZV"},"source":["validation = True\n","start_time = time.time()\n","pool = concurrent.futures.ProcessPoolExecutor(max_workers=None)\n","pool.map(create_images, range(250))\n","pool.shutdown(wait=True)\n","print(\"time:\",time.time()-start_time,\"per1k:\",(time.time()-start_time)/.25,\"per1:\",(time.time()-start_time)/250)\n","\n","model_path = get_model_path(model_path_txt)\n","config = get_config(model_path, architecture, batch_size, saved_folder, actual_epoch, learning_rate)\n","\n","K.clear_session()\n","setup_inference(config, model_path)"],"execution_count":null,"outputs":[]}]}